{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMFThy7KNix/BAk6YdmOfNw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jonghhhh/lecture_colabs/blob/main/%EC%9D%B4%EB%AF%B8%EC%A7%80_%EC%9C%A0%EC%82%AC%EB%8F%84_%EA%B2%80%EC%83%89%EA%B3%BC_%ED%81%B4%EB%9F%AC%EC%8A%A4%ED%84%B0%EB%A7%81_CLIP_ViT_FAISS_K_means_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 이미지 유사도 검색과 클러스터링: CLIP, ViT, FAISS, K-means 활용"
      ],
      "metadata": {
        "id": "WRDSEqs6jGV4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### CLIP (Contrastive Language–Image Pre-Training)\n",
        "- OPEN AI의 이미지와 텍스트를 함께 학습하는 모델로, 자연어와 시각적 표현을 결합하여 강력한 인식 성능 제공\n",
        "\n",
        "### ViT-B/32\n",
        "- Vision Transformer 모델의 변형으로, 이미지 입력을 토큰화하여 트랜스포머 아키텍처에 전달\n",
        "- B = Base 모델.\n",
        "- 32 = 이미지가 32x32 픽셀 패치로 분할되어 입력\n",
        "\n",
        "### FAISS(Facebook AI Similarity Search)\n",
        "- 대규모 벡터 검색 및 클러스터링을 위한 라이브러리. 주로 고차원 벡터의 빠른 유사성 검색을 수행\n",
        "\n",
        "### K-means 클러스터링\n",
        "- 비지도 학습 알고리즘으로, 데이터를 여러 그룹(클러스터)으로 나누는 데 사용"
      ],
      "metadata": {
        "id": "dmF1jX75jGV-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 패키지 설치\n",
        "!pip install ftfy regex tqdm   # 아래 CLIP 전처리에 필요. ftfy: 텍스트를 깨끗하게 수정\n",
        "!pip install git+https://github.com/openai/CLIP.git\n",
        "!pip install faiss-gpu\n",
        "!pip install torchvision\n",
        "!pip install numpy\n",
        "!pip install pillow"
      ],
      "metadata": {
        "id": "-jJIliNaXMyK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 검색: 전체 데이터에서 유사한 이미지 찾기(코사인유사도)"
      ],
      "metadata": {
        "id": "T3NGVzYIkpGV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import clip\n",
        "from PIL import Image, ImageOps\n",
        "import faiss\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.manifold import TSNE\n",
        "import pandas as pd\n",
        "import pickle\n",
        "from scipy.spatial.distance import cdist\n",
        "\n",
        "# CLIP 모델 로드 및 설정\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model, preprocess = clip.load(\"ViT-B/32\", device=device) # CLIP 모델과 해당 전처리 함수를 로드. preprocess: 이미지 전처리.\n",
        "\n",
        "# 이미지 벡터화 함수\n",
        "def get_image_vector(image_path, model, preprocess):\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    image = ImageOps.grayscale(image)  # 이미지 흑백 변환\n",
        "    image = image.convert('RGB')  # 모델이 RGB 입력을 기대하므로 다시 RGB로 변환\n",
        "    image = preprocess(image).unsqueeze(0).to(device)\n",
        "    with torch.no_grad():\n",
        "        image_features = model.encode_image(image)\n",
        "    vector = image_features.cpu().numpy().squeeze()\n",
        "    return vector\n",
        "\n",
        "# 이미지 폴더 경로 설정\n",
        "image_folder = '/--image_folder/'\n",
        "\n",
        "# 이미지 벡터와 경로 저장을 위한 리스트\n",
        "image_vectors = []\n",
        "image_paths = []\n",
        "\n",
        "# 이미지 벡터화 및 경로 저장\n",
        "for filename in os.listdir(image_folder):\n",
        "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
        "        image_path = os.path.join(image_folder, filename)\n",
        "        vector = get_image_vector(image_path, model, preprocess)\n",
        "        image_vectors.append(vector)\n",
        "        image_paths.append(filename)  # 경로 대신 파일 이름만 저장\n",
        "\n",
        "# 리스트를 numpy 배열로 변환\n",
        "image_vectors = np.array(image_vectors).astype(np.float32)\n",
        "\n",
        "# 벡터 정규화 (L2 정규화) - 코사인 유사도를 위해\n",
        "faiss.normalize_L2(image_vectors)\n",
        "\n",
        "# GPU 사용을 위한 설정\n",
        "res = faiss.StandardGpuResources()\n",
        "index_flat = faiss.IndexFlatIP(image_vectors.shape[1])  # 코사인 유사도를 위한 Inner Product\n",
        "gpu_index = faiss.index_cpu_to_gpu(res, 0, index_flat)\n",
        "\n",
        "# Faiss 인덱스에 데이터 추가\n",
        "gpu_index.add(image_vectors)\n",
        "\n",
        "def find_similar_images(query_image_path, top_k=5):  # top_k: 상위 몇 개의 이미지를 반환할지 결정\n",
        "    # 쿼리 이미지 벡터화\n",
        "    query_vector = get_image_vector(query_image_path, model, preprocess).astype(np.float32)\n",
        "    faiss.normalize_L2(query_vector.reshape(1, -1))\n",
        "\n",
        "    # 코사인 유사도 계산 (내적을 사용하여)\n",
        "    D, I = gpu_index.search(query_vector.reshape(1, -1), top_k)\n",
        "\n",
        "    # 유사한 이미지와 유사도 데이터프레임 생성\n",
        "    similar_images = [image_paths[i] for i in I[0]]\n",
        "    similarities = 1 - D[0]  # 거리를 유사도로 변환\n",
        "    df_similar = pd.DataFrame({'image': similar_images, 'cosine_similarity': similarities})\n",
        "\n",
        "    # 유사도 내림차순으로 정렬\n",
        "    df_similar = df_similar.sort_values(by='cosine_similarity', ascending=False).reset_index(drop=True)\n",
        "    return df_similar\n",
        "\n",
        "# 예제 쿼리 이미지 경로\n",
        "query_image_path = 'new_image.jpg'\n",
        "\n",
        "# 유사한 이미지 검색 및 결과 출력\n",
        "df_similar_images = find_similar_images(query_image_path)\n",
        "print(df_similar_images)"
      ],
      "metadata": {
        "id": "aFqlOrNqhghx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 군집분석(clustering)"
      ],
      "metadata": {
        "id": "sXOSEbg1wuwm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### K-means에서 적절한 군집 개수 찾기(Elbow Method) 함수화\n",
        "- 군집(클러스터) 수에 따른 WCSS(Within-Cluster Sum of Squares) 계산해, WCSS가 급격히 감소했다 완화하는 지점 찾기"
      ],
      "metadata": {
        "id": "RUlwj9gPwuwm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-gpu\n",
        "!pip install matplotlib\n",
        "\n",
        "import faiss\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def calculate_wcss(document_vectors):\n",
        "    wcss = []\n",
        "    for i in range(1, 11):\n",
        "        kmeans = faiss.Kmeans(d=document_vectors.shape[1], k=i, niter=20, gpu=True)\n",
        "        kmeans.train(document_vectors)\n",
        "        wcss.append(kmeans.obj[-1])\n",
        "    return wcss"
      ],
      "metadata": {
        "id": "upMquy53wuwm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 군집분석: 코사인 유사도 사용"
      ],
      "metadata": {
        "id": "_oMV5mU6xgwr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import clip\n",
        "from PIL import Image, ImageOps\n",
        "import faiss\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.manifold import TSNE\n",
        "import pandas as pd\n",
        "import pickle\n",
        "\n",
        "\n",
        "# CLIP 모델 로드 및 설정\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
        "\n",
        "# 이미지 벡터화 함수\n",
        "def get_image_vector(image_path, model, preprocess):\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    image = ImageOps.grayscale(image)  # 이미지 흑백 변환\n",
        "    image = image.convert('RGB')  # 모델이 RGB 입력을 기대하므로 다시 RGB로 변환\n",
        "    image = preprocess(image).unsqueeze(0).to(device)\n",
        "    with torch.no_grad():\n",
        "        image_features = model.encode_image(image)\n",
        "    vector = image_features.cpu().numpy().squeeze()\n",
        "    return vector\n",
        "\n",
        "# 이미지 폴더 경로 설정\n",
        "image_folder = '/content/drive/MyDrive/gwanjingu/dance/'\n",
        "\n",
        "# 이미지 벡터와 경로 저장을 위한 리스트\n",
        "image_vectors = []\n",
        "image_paths = []\n",
        "\n",
        "# 이미지 벡터화 및 경로 저장\n",
        "for filename in os.listdir(image_folder):\n",
        "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
        "        image_path = os.path.join(image_folder, filename)\n",
        "        vector = get_image_vector(image_path, model, preprocess)\n",
        "        image_vectors.append(vector)\n",
        "        image_paths.append(filename)  # 경로 대신 파일 이름만 저장\n",
        "\n",
        "# 리스트를 numpy 배열로 변환\n",
        "image_vectors = np.array(image_vectors).astype(np.float32)\n",
        "\n",
        "# 벡터 정규화 (L2 정규화) - 코사인 유사도를 위해\n",
        "faiss.normalize_L2(image_vectors)\n",
        "\n",
        "# GPU 사용을 위한 설정\n",
        "res = faiss.StandardGpuResources()\n",
        "index_flat = faiss.IndexFlatIP(image_vectors.shape[1])  # 코사인 유사도를 위한 Inner Product\n",
        "gpu_index = faiss.index_cpu_to_gpu(res, 0, index_flat)\n",
        "\n",
        "# 클러스터 개수 도출: WCSS 계산\n",
        "wcss = calculate_wcss(document_vectors)\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(range(1, 11), wcss, marker='o')\n",
        "plt.title('Elbow Method For Optimal k')\n",
        "plt.xlabel('Number of clusters')\n",
        "plt.ylabel('WCSS')\n",
        "plt.show()\n",
        "\n",
        "# Faiss를 이용한 클러스터링\n",
        "num_clusters = 4  # 위에서 확인한 최적의 cluster 개수 입력\n",
        "kmeans = faiss.Kmeans(d=image_vectors.shape[1], k=num_clusters, niter=100, gpu=True, spherical=True)  # spherical=True로 설정하여 클러스터링시 벡터를 정규화\n",
        "kmeans.train(image_vectors)\n",
        "\n",
        "# 클러스터 할당\n",
        "_, cluster_assignments = kmeans.index.search(image_vectors, 1)\n",
        "cluster_assignments = cluster_assignments.flatten()  # 2D 배열에서 1D 배열로 변환\n",
        "\n",
        "# 클러스터 중심점 확인과 저장\n",
        "cluster_centroids = kmeans.centroids\n",
        "cluster_centroids.shape\n",
        "with open('cluster_centroids.pkl', 'wb') as f:\n",
        "    pickle.dump(cluster_centroids, f)\n",
        "\n",
        "# 클러스터 중심점과의 유사도 계산\n",
        "similarities = []\n",
        "for i, vector in enumerate(image_vectors):\n",
        "    cluster_idx = cluster_assignments[i]\n",
        "    centroid = cluster_centroids[cluster_idx]\n",
        "    similarity = 1 - cdist([vector], [centroid], metric='cosine')[0][0]  # 코사인 유사도 계산\n",
        "    similarities.append(similarity)\n",
        "\n",
        "# 클러스터 결과를 DataFrame으로 변환\n",
        "df_clustered = pd.DataFrame({'image': image_paths, 'cluster': cluster_assignments, 'cosine_similarity_to_centroid': similarities})\n",
        "df_clustered"
      ],
      "metadata": {
        "id": "xc4nxNXL4Zdx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 시각화: t-SNE(t-distributed Stochastic Neighbor Embedding) 활용"
      ],
      "metadata": {
        "id": "CcXfHVZfxVxo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "\n",
        "# TSNE 변환\n",
        "data_with_centroids = np.vstack([image_vectors, cluster_centroids])\n",
        "perplexity = min(30, len(image_vectors) - 1)  # perplexity 값을 샘플 수보다 작게 설정\n",
        "tsne = TSNE(n_components=2, perplexity=perplexity, random_state=42)\n",
        "tsne_results = tsne.fit_transform(data_with_centroids)\n",
        "\n",
        "# TSNE 결과를 DataFrame으로 변환\n",
        "df_tsne = pd.DataFrame(tsne_results[:len(image_vectors)], columns=['x', 'y'])\n",
        "df_tsne['image'] = image_paths\n",
        "df_tsne['cluster'] = cluster_assignments\n",
        "\n",
        "# TSNE 결과 시각화\n",
        "plt.figure(figsize=(10, 8))\n",
        "for cluster in range(num_clusters):\n",
        "    clustered = df_tsne[df_tsne['cluster'] == cluster]\n",
        "    plt.scatter(clustered['x'], clustered['y'], label=f'Cluster {cluster}')\n",
        "\n",
        "# 중심점 시각화\n",
        "centroid_tsne = tsne_results[len(image_vectors):]\n",
        "for i, centroid in enumerate(centroid_tsne):\n",
        "    plt.scatter(centroid[0], centroid[1], marker='X', s=200, label=f'Centroid {i}', edgecolor='black')\n",
        "\n",
        "plt.legend()\n",
        "plt.title('t-SNE Results')\n",
        "plt.xlabel('t-SNE Dimension 1')\n",
        "plt.ylabel('t-SNE Dimension 2')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ptM9Te2JSHjx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}