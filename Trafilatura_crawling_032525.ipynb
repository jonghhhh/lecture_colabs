{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOuXXuyzy7tfhfKsellAD4+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jonghhhh/lecture_colabs/blob/main/Trafilatura_crawling_032525.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trafilatura: 쉬운 웹 텍스트 스크래핑"
      ],
      "metadata": {
        "id": "Xd8By6aWodQ6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## trafilatura\n",
        "- 이탈리아어로 '압출' 또는 '추출' 의미\n",
        "- 웹 크롤링을 쉽고 효율적으로 수행할 수 있게 해주는 Python 라이브러리.\n",
        "- 웹 페이지에서 중요한 텍스트 콘텐츠(본문, 제목, 메타데이터)를 다양한 형식으로 쉽게 추출.\n",
        "\n",
        "## 주요 특징\n",
        "1. **간결한 코드**: 몇 줄의 코드만으로 HTML에서 핵심 콘텐츠 추출\n",
        "2. **자동 콘텐츠 감지**: 웹 페이지의 구조를 분석하여 중요한 내용을 자동으로 구분\n",
        "3. **다양한 출력 형식**: txt, XML, JSON, CSV, MARKDOWN 등 다양한 형식으로 결과 출력\n",
        "4. **메타데이터 추출**: 제목, 작성자, 날짜, 카테고리 등의 메타데이터도 함께 추출\n",
        "5. **다국어 지원**: 한국어를 포함한 다양한 언어로 된 웹 페이지 처리"
      ],
      "metadata": {
        "id": "rKHcRvAuoZlr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 설치"
      ],
      "metadata": {
        "id": "dMJrdGypqVbi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# trafilatura 설치\n",
        "!pip install trafilatura"
      ],
      "metadata": {
        "id": "hSPIdcOOHHAn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_0EbA-FXoOlO"
      },
      "outputs": [],
      "source": [
        "# 필요한 라이브러리 임포트\n",
        "import trafilatura\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "from IPython.display import HTML, display\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. 기본 사용법\n",
        "\n",
        "trafilatura의 가장 기본적인 사용 방법은 두 단계로 이루어짐\n",
        "\n",
        "1. `fetch_url()` 함수로 웹 페이지 다운로드\n",
        "2. `extract()` 함수로 웹 페이지에서 콘텐츠 추출\n"
      ],
      "metadata": {
        "id": "tLqAIOUQqM3G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 단일 URL에서 텍스트 추출"
      ],
      "metadata": {
        "id": "IANuUhSEqQpz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 웹 페이지 다운로드 및 콘텐츠 추출\n",
        "url = 'https://n.news.naver.com/mnews/article/079/0004008336'\n",
        "downloaded = trafilatura.fetch_url(url)\n",
        "\n",
        "# 기본 텍스트 추출\n",
        "result = trafilatura.extract(downloaded)\n",
        "\n",
        "# 결과 출력 (앞부분 1000자만)\n",
        "print(\"URL:\", url)\n",
        "print(\"추출된 텍스트 (앞부분):\", result[:1000] if result else \"콘텐츠 추출 실패\")\n",
        "print(\"추출된 텍스트 길이:\", len(result) if result else 0, \"자\")"
      ],
      "metadata": {
        "id": "7O57hIiEoZFs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 메타데이터 추출"
      ],
      "metadata": {
        "id": "jWxniVMbqKca"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 메타데이터와 함께 추출\n",
        "'''메타데이터_변수 = ['title', 'author', 'hostname', 'date', 'fingerprint', 'id',\n",
        "'license', 'comments', 'raw_text', 'text', 'language', 'image', 'pagetype',\n",
        "'filedate', 'source', 'source-hostname', 'excerpt', 'categories', 'tags']'''\n",
        "\n",
        "result_with_metadata = trafilatura.extract(downloaded, output_format='json', with_metadata=True)\n",
        "\n",
        "# JSON 문자열을 파이썬 사전으로 변환\n",
        "if result_with_metadata:\n",
        "    metadata_dict = json.loads(result_with_metadata)\n",
        "\n",
        "# 데이터프레임으로 출력\n",
        "pd.DataFrame([metadata_dict])\n",
        "\n",
        "# 깔끔하게 출력\n",
        "print(\"제목:\", metadata_dict.get('title', '정보 없음'))\n",
        "print(\"작성자:\", metadata_dict.get('author', '정보 없음'))\n",
        "print(\"날짜:\", metadata_dict.get('date', '정보 없음'))\n",
        "print(\"설명:\", metadata_dict.get('description', '정보 없음'))\n",
        "print(\"언어:\", metadata_dict.get('language', '정보 없음'))\n",
        "print(\"카테고리:\", metadata_dict.get('categories', '정보 없음'))\n",
        "print(\"태그:\", metadata_dict.get('tags', '정보 없음'))\n",
        "print(\"사이트 이름:\", metadata_dict.get('sitename', '정보 없음'))\n",
        "print(\"\\n본문 내용 (앞부분):\", metadata_dict.get('text', '')[:500] + '...' if metadata_dict.get('text') else \"콘텐츠 없음\")"
      ],
      "metadata": {
        "id": "NmmlcTLpoZBm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. 다양한 출력 형식\n",
        "\n",
        "trafilatura는 다양한 출력 형식을 지원:\n",
        "\n",
        "- **텍스트(txt)**: 기본 형식, 일반 텍스트로 콘텐츠 추출\n",
        "- **JSON**: 구조화된 JSON 형식으로 메타데이터와 본문 제공\n",
        "- **XML**: XML 형식으로 문서 구조 유지\n",
        "- **CSV**: 테이블 형식으로 데이터 저장에 유용\n",
        "- **MARKDOWN**: 마크다운 형식으로 제목, 링크 등의 구조 유지\n",
        "\n",
        "출력 형식은 `extract()` 함수의 `output_format` 매개변수로 지정."
      ],
      "metadata": {
        "id": "tAFjfZ0TqGHk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 출력 형식 예제"
      ],
      "metadata": {
        "id": "BD6wMheGqD6E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 다양한 출력 형식 비교\n",
        "formats = ['txt', 'json', 'xml', 'csv', 'markdown']\n",
        "results = {}\n",
        "\n",
        "for fmt in formats:\n",
        "    result = trafilatura.extract(downloaded, output_format=fmt)\n",
        "    results[fmt] = result[:500] + '...' if result and len(result) > 500 else result\n",
        "\n",
        "# 결과 출력\n",
        "for fmt, result in results.items():\n",
        "    print(f\"\\n===== {fmt.upper()} 형식 =====\")\n",
        "    print(result)"
      ],
      "metadata": {
        "id": "JtpYmbUkoY82"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. 고급 설정\n",
        "\n",
        "다양한 옵션을 통해 웹 페이지 추출 방식을 세밀하게 제어\n",
        "\n",
        "- **include_comments**: 댓글 포함 여부 (기본값: True)\n",
        "- **include_tables**: 테이블 포함 여부 (기본값: True)\n",
        "- **include_images**: 이미지 참조 포함 여부 (기본값: True)\n",
        "- **include_links**: 링크 포함 여부 (기본값: True)\n",
        "- **no_fallback**: 메인 알고리즘 실패 시 대체 알고리즘 사용 여부 (기본값: False)\n",
        "- **favor_precision**: 정확도 우선(True) 또는 재현율 우선(False) (기본값: False)\n",
        "- **target_language**: 특정 언어로 된 콘텐츠만 추출 (예: 'ko', 'en')"
      ],
      "metadata": {
        "id": "AJ5vPQQbozqt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 고급 설정 예제"
      ],
      "metadata": {
        "id": "zteGA0HSp__o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 다양한 설정 옵션 사용 예제\n",
        "# 1. 모든 옵션 켜기\n",
        "full_option = trafilatura.extract(\n",
        "    downloaded,\n",
        "    include_comments=True,\n",
        "    include_tables=True,\n",
        "    include_images=True,\n",
        "    include_links=True,\n",
        "    output_format='txt'\n",
        ")\n",
        "\n",
        "# 2. 최소 옵션 (순수 텍스트만)\n",
        "minimal_option = trafilatura.extract(\n",
        "    downloaded,\n",
        "    include_comments=False,\n",
        "    include_tables=False,\n",
        "    include_images=False,\n",
        "    include_links=False,\n",
        "    output_format='txt'\n",
        ")\n",
        "\n",
        "# 결과 비교\n",
        "print(\"== 모든 옵션 켜기 (전체 콘텐츠) ==\")\n",
        "print(full_option[:500], \"...\\n\") if full_option else print(\"추출 실패\\n\")\n",
        "\n",
        "print(\"== 최소 옵션 (순수 텍스트만) ==\")\n",
        "print(minimal_option[:500], \"...\") if minimal_option else print(\"추출 실패\")\n",
        "\n",
        "# 텍스트 길이 비교\n",
        "if full_option and minimal_option:\n",
        "    print(f\"\\n전체 콘텐츠 길이: {len(full_option)} 자\")\n",
        "    print(f\"순수 텍스트 길이: {len(minimal_option)} 자\")\n",
        "    print(f\"차이: {len(full_option) - len(minimal_option)} 자\")"
      ],
      "metadata": {
        "id": "9nXWjf0XoY05"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. 여러 URL 처리\n",
        "\n",
        "여러 웹 페이지를 한 번에 크롤링해야 하는 경우, 여러 URL을 효율적으로 처리\n",
        "\n",
        "- 반복문 사용: `trafilatura.fetch_url()`와 `trafilatura.extract()`를 반복문에서 순차적으로 사용\n",
        "- concurrent.futures 모듈 사용: Python의 표준 라이브러리인 concurrent.futures를 사용하여 병렬 처리\n",
        "- trafilatura.crawl 모듈 사용: 현재 작동 어려움\n"
      ],
      "metadata": {
        "id": "Oydr5NqLp44I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 테스트할 URL 목록\n",
        "urls = [\n",
        "    \"https://www.domin.co.kr/news/articleView.html?idxno=1500714\",  # 지역지\n",
        "    \"https://www.ohmynews.com/NWS_Web/View/at_pg.aspx?CNTN_CD=A0003099071&CMPT_CD=P0010&utm_source=naver&utm_medium=newsearch&utm_campaign=naver_news\",  # 인터넷언론\n",
        "    \"https://www.sisajournal-e.com/news/articleView.html?idxno=218656\",  # 잡지\n",
        "    \"https://news.tvchosun.com/site/data/html_dir/2025/02/03/2025020390247.html?_gl=1*60n6cu*_ga*MTY2MDQ5OTkwNy4xNzM4NTgxMTYw*_ga_D5GZR50LJV*MTczODYzODM5MS4yLjEuMTczODYzODQxOC4zMy4wLjA.\",  # 방송1\n",
        "    \"https://news.sbs.co.kr/news/endPage.do?news_id=N1007969124&plink=THUMB&cooper=SBSNEWSPROGRAM\",  # 방송2\n",
        "    \"https://www.yna.co.kr/view/AKR20250130040200053?input=1195m\",  # 통신사\n",
        "    \"https://m.skyedaily.com/news_view.html?ID=256827\"  # 추출 안되는 경우\n",
        "]\n",
        "\n",
        "# 1. 기본 순차 처리: 반복문 사용\n",
        "print(\"1. 순차 처리 방식\")\n",
        "start_time = time.time()\n",
        "results_sequential = []\n",
        "\n",
        "for url in urls:\n",
        "    try:\n",
        "        downloaded = trafilatura.fetch_url(url)\n",
        "        if downloaded:\n",
        "            result = trafilatura.extract(downloaded, output_format='json', with_metadata=True)\n",
        "            if result:\n",
        "                results_sequential.append(json.loads(result))\n",
        "            else:\n",
        "                print(f\"콘텐츠 추출 실패: {url}\")\n",
        "        else:\n",
        "            print(f\"다운로드 실패: {url}\")\n",
        "    except Exception as e:\n",
        "        print(f\"오류 발생: {url} - {e}\")\n",
        "\n",
        "sequential_time = time.time() - start_time\n",
        "print(f\"순차 처리 시간: {sequential_time:.2f}초\")\n",
        "print(f\"성공적으로 처리된 URL: {len(results_sequential)}/{len(urls)}\\n\")\n",
        "print(results_sequential)\n",
        "\n",
        "# 2. concurrent.futures를 사용한 병렬 처리\n",
        "import concurrent.futures\n",
        "\n",
        "def process_url(url):\n",
        "    try:\n",
        "        downloaded = trafilatura.fetch_url(url)\n",
        "        if downloaded:\n",
        "            result = trafilatura.extract(downloaded, output_format='json', with_metadata=True)\n",
        "            if result:\n",
        "                return json.loads(result)\n",
        "        return None\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "print(\"2. 병렬 처리 방식\")\n",
        "start_time = time.time()\n",
        "\n",
        "with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:\n",
        "    results_parallel = list(filter(None, executor.map(process_url, urls)))\n",
        "\n",
        "parallel_time = time.time() - start_time\n",
        "print(f\"병렬 처리 시간: {parallel_time:.2f}초\")\n",
        "print(f\"성공적으로 처리된 URL: {len(results_parallel)}/{len(urls)}\")\n",
        "print(f\"속도 향상: {sequential_time/parallel_time:.2f}배\\n\")\n",
        "print(results_parallel)"
      ],
      "metadata": {
        "id": "WgZymXeLo5hk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. trafilatura와 다른 라이브러리 비교\n",
        "\n",
        "### 5.1. 주요 라이브러리 비교\n",
        "\n",
        "| 라이브러리 | 주요 특징 | 장점 | 단점 |\n",
        "|----------|---------|------|------|\n",
        "| **trafilatura** | 콘텐츠 추출 특화 | 간결한 코드, 자동 콘텐츠 감지, 다양한 출력 형식 | HTML 구조 조작에 제한적 |\n",
        "| **BeautifulSoup** | HTML/XML 파싱 | 세밀한 HTML 조작, 유연성 | 콘텐츠 추출에 추가 로직 필요 |\n",
        "| **Scrapy** | 대규모 크롤링 | 완전한 크롤링 프레임워크, 분산 크롤링 | 학습 곡선이 높음, 설정이 복잡 |\n",
        "| **newspaper3k** | 뉴스 기사 특화 | 뉴스 전용 기능, NLP 지원 | 뉴스 외 콘텐츠에 제한적 |\n",
        "| **requests-html** | 최신 파싱 라이브러리 | JavaScript 실행 지원, 간결한 API | 성능이 상대적으로 낮을 수 있음 |\n",
        "\n",
        "### 5.2. 사용 시나리오별 권장 라이브러리\n",
        "\n",
        "- **뉴스 기사 크롤링**: trafilatura, newspaper3k\n",
        "- **복잡한 웹 구조 파싱**: BeautifulSoup, lxml\n",
        "- **대규모 웹 크롤링**: Scrapy\n",
        "- **JavaScript 렌더링 필요**: Selenium, Playwright, requests-html\n",
        "- **빠른 프로토타이핑**: trafilatura, requests-html\n",
        "\n",
        "trafilatura는 특히 블로그, 뉴스 기사, 포럼 등의 텍스트 중심 웹사이트에서 콘텐츠를 추출하는 데 우수함."
      ],
      "metadata": {
        "id": "qVs9_RibpC82"
      }
    }
  ]
}